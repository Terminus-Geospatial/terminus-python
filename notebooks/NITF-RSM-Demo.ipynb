{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  NITF Replacement Sensor Model (RSM) Demo\n",
    "\n",
    "This notebook demonstrates how to create an RSM TRE for a given image.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benefits of the RSM over \"4-corners\" and SENSRB\n",
    "\n",
    "1. No knowledge of the underlying camera is required.  The embedded polynomials abstract everything.\n",
    "2. The imagery provider (You), no longer need to actually ortho-rectify the imagery.  Simply convert the imagery to the expected color-space, apply any color corrections, then write to disk.  The RSM can allow a downstream user to optionally apply ortho-rectification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to SENSRB \"Geo-Transform\"\n",
    "\n",
    "The SENSRB TRE attempts to represent the imagery position using a 2-8 term geometric transform.   Per <insert citation>, they take one of the following forms. \n",
    "\n",
    "In this demo, we use the 6-term transform.  This is because it matches the GDAL API's \"geotransform\".  This is a commonly used equation in the GIS community and is easy to port. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Rational Polynomial Coefficients\n",
    "\n",
    "RPCs are composed of 4 20-term polynomal coefficients. \n",
    "\n",
    "* **Rational Polynomial Coefficients:**\n",
    "   * Pixel Columns (X)\n",
    "      * $\\overline{N_c} = \\begin{bmatrix} N_{C_1}, N_{C_2}, N_{C_3}, \\cdot, N_{C_20} \\end{bmatrix}$\n",
    "      * $\\overline{D_c} = \\begin{bmatrix} D_{C_1}, D_{C_2}, D_{C_3}, \\cdot, D_{C_20} \\end{bmatrix}$\n",
    "   * Pixel Rows (Y) \n",
    "      * $\\overline{N_r} = \\begin{bmatrix} N_{R_1}, N_{R_2}, N_{R_3}, \\cdot, N_{R_20} \\end{bmatrix}$\n",
    "      * $\\overline{D_r} = \\begin{bmatrix} D_{R_1}, D_{R_2}, D_{R_3}, \\cdot, D_{R_20} \\end{bmatrix}$\n",
    "\n",
    "<br>\n",
    "\n",
    "These coefficients are used to convert geographic coordinates into pixel coordinates. \n",
    "\n",
    "* **Geographic Coordinates:**\n",
    "   * $\\overline{W} = \\begin{bmatrix} \\lambda, \\phi, H \\end{bmatrix}$\n",
    "      * $\\lambda$ - Longitude in decimal degrees.\n",
    "      * $\\phi$ - Latitude in decimal degrees.\n",
    "      * $H$ - Height above the WGS84 ellipsoid. \n",
    "\n",
    "<br>\n",
    "\n",
    "* **Pixel Coordinates:**\n",
    "   * $\\overline{P} = \\left[ X_P, Y_P\\right]$\n",
    "      * $X_P$ - Pixel columns, ***scan***-position, X-value.\n",
    "      * $Y_P$ - Pixel rows, ***line***-position, Y-value.\n",
    "\n",
    "<br>\n",
    "\n",
    "Note, that these values need to be ***normalized***.  This is performed with a set of terms.\n",
    "\n",
    "* $\\lambda_\\texttt{off}$ - Longitude offset.\n",
    "* $\\phi_\\texttt{off}$ - Latitude offset.\n",
    "* $H_\\texttt{off}$ - Height offset.\n",
    "\n",
    "* $\\lambda_\\texttt{scale}$ - Longitude scale.\n",
    "* $\\phi_\\texttt{scale}$ - Latitude scale.\n",
    "* $H_\\texttt{scale}$ - Height scale.\n",
    "\n",
    "When converting from ***World*** to ***Pixel*** coordinates, we first normalize the geographic coordinates. \n",
    "\n",
    "$$\n",
    "L = \\frac{\\lambda - \\lambda_\\texttt{off}}{\\lambda_\\texttt{scale}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "P = \\frac{\\phi - \\phi_\\texttt{off}}{\\phi_\\texttt{scale}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "H = \\frac{H - H_\\texttt{off}}{H_\\texttt{scale}}\n",
    "$$\n",
    "\n",
    "From our normalized coordinates, we can create the terms we will apply to our polynomial. \n",
    "\n",
    "$$\n",
    "\\rho \\left( L, P, H \\right) = \\begin{bmatrix} 1, & L, &  P, & H, & L \\cdot P, & L \\cdot H, & P \\cdot H, & L^2, & P^2, & H^2, & P \\cdot L \\cdot H, & L^3, & L \\cdot P^2, & L \\cdot H^2, & L^2 \\cdot P, & P^3, & P \\cdot H^2, & L^2 \\cdot H, & P^2 \\cdot H, & H^3 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Now, simply multiply our $\\rho \\left( L, P, H \\right)$ value against the numerators and denominators.  The fraction then resolves via the following.\n",
    "\n",
    "$$\n",
    "{X_P}' = \\frac{\\overline{N_c} \\cdot \\rho \\left( L, P, H \\right)}{\\overline{D_c} \\cdot \\rho \\left( L, P, H \\right)}\n",
    "$$\n",
    "$$\n",
    "{Y_P}' = \\frac{\\overline{N_r} \\cdot \\rho \\left( L, P, H \\right)}{\\overline{D_r} \\cdot \\rho \\left( L, P, H \\right)}\n",
    "$$\n",
    "\n",
    "Lastly, apply the pixel scale and offset values. \n",
    "\n",
    "$$\n",
    "X_P = \\frac{{X_P}' - X_\\texttt{off}}{X_\\texttt{scale}}\n",
    "$$\n",
    "$$\n",
    "Y_P = \\frac{{Y_P}' - Y_\\texttt{off}}{Y_\\texttt{scale}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0 - Setup Preconditions\n",
    "\n",
    "First, we have our required Python packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Python Libraries\n",
    "import datetime\n",
    "import glob\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "\n",
    "#  URL Lib for Fetching Imagery\n",
    "from urllib.request import urlopen\n",
    "\n",
    "#  Pandas Data Science API\n",
    "import pandas as pd\n",
    "\n",
    "#  OpenCV\n",
    "import cv2\n",
    "\n",
    "#  Numpy \n",
    "import numpy as np\n",
    "float_formatter = \"{:.2f}\".format\n",
    "np.set_printoptions(formatter={'float_kind':float_formatter})\n",
    "\n",
    "#  Plotly Visualization\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express       as px\n",
    "import plotly.subplots      as sp\n",
    "\n",
    "#  Progress Bar Support\n",
    "from tqdm import notebook as tqdm\n",
    "\n",
    "#  Terminus Python Libraries\n",
    "sys.path.append( '../src' )\n",
    "from tmns.dem.gtiff import DEM_File as DEM\n",
    "import tmns.math.geometry as geom\n",
    "import tmns.net.wms as wms\n",
    "from tmns.proj.RPC00B import RPC00B\n",
    "from tmns.proj.SENSRB import SENSRB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare a logger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig( level = logging.INFO )\n",
    "logger = logging.getLogger( 'NITF RSM Demo' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our image is from April 23, 2002."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'ARUDEN000040045.2.tif'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Path to SRTM Elevation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srtm_path = 'SRTM_GL1.tif'\n",
    "dem = DEM( srtm_path )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have already run this model, you can skip the WMS and GCP checks to save time and disk space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite_crops = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be verifying our Ground Control Points via a comparison against USDA NAIP imagery.  This is available from the US Government via a Web-Map-Service (WMS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  URL to ArcGIS Hosted NAIP imagery\n",
    "wms_url = 'https://gis.apfo.usda.gov/arcgis/services/NAIP/USDA_CONUS_PRIME/ImageServer/WMSServer?service=WMS'\n",
    "\n",
    "# USDA_CONUS_PRIME\n",
    "wms_layers = ['0']\n",
    "\n",
    "#  Image Format\n",
    "wms_format = 'image/png'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Load Non-Orthorectified Image\n",
    "In this demo, we have an aerial photograph of Denver's City Park taken in 2002.  This photo is used because it is not orthorectified.  We will need to manually determine a camera model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_bands = cv2.cvtColor( cv2.imread( img_path, cv2.IMREAD_COLOR ), cv2.COLOR_BGR2RGB )\n",
    "print(img_bands.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = go.Figure()\n",
    "fig1.add_trace( go.Image( z = img_bands ) )\n",
    "fig1.update_layout( title = 'USGS Aerial Photo, 4/23/2002',\n",
    "                    height = 900 )\n",
    "fig1.show( renderer = 'png' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As will be shown below, this image was provided with baseline corner data.  Those corners provide an estimate, but are not exact.  Here is an illustration of the projection error. Blue denotes a pair of roads in the image and red is the same pair of roads in OpenStreetMap.\n",
    "\n",
    "<img src=\"./docs/current-alignment.png\" style=\"height:600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating the Geo-Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "img_df = pd.DataFrame( { 'Attribute': ['Acquisition Date', 'Flight Altitude (ft)', 'Focal Length (mm)',\n",
    "                                       'Film Width (mm)', 'Film Height (mm)',\n",
    "                                       'Center Lat', 'Center Lon',\n",
    "                                       'NW Lat', 'NW Lon', 'NE Lat', 'NE Lon',\n",
    "                                       'SE Lat', 'SE Lon', 'SW Lat', 'SE Lon',\n",
    "                                       'Pitch Angle', 'Yaw Angle', 'Roll Angle' ],\n",
    "                         'Value': [ datetime.datetime( year = 2002, month = 4, day = 23 ),\n",
    "                                    7500, 152.77, 229, 229,\n",
    "                                    39.750006, -104.95283,\n",
    "                                    39.765563, -104.972699, 39.765335, -104.932675,\n",
    "                                    39.734448, -104.932979, 39.734676, -104.972985,\n",
    "                                    -1.3, -8.7, 0.0 ] } )\n",
    "display( img_df )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will assume the aircraft position is directly above the center point.  Given the camera rotation is not perfectly level, this will require adjustments later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_lla = [ img_df.loc[img_df['Attribute'] == 'Center Lon'].values[0][1],\n",
    "                 img_df.loc[img_df['Attribute'] == 'Center Lat'].values[0][1],\n",
    "                 img_df.loc[img_df['Attribute'] == 'Flight Altitude (ft)'].values[0][1] * 3.28084]\n",
    "display( position_lla )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Black Box Sensor Model\n",
    "\n",
    "In order to show the value of this camera model, we need to show the \"complex\" model which is likely proprietary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel:\n",
    "\n",
    "    def __init__(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mark Ground Control Points\n",
    "\n",
    "We have a set of Ground-Control-Points in the attached file. The first few are shown for context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcp_df = pd.read_csv( 'GCPs.csv' )\n",
    "mean_elevation = gcp_df['Elevation'].mean()\n",
    "gcp_df['Elevation'] = mean_elevation\n",
    "display( gcp_df.head(5) )\n",
    "display( f'Total of {gcp_df.shape[0]} GCPs loaded' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying Accuracy of GCPs\n",
    "This is a highly error prone process.  To verify all inputs, we have a set of steps. \n",
    "\n",
    "- Verify the pixel locations by drawing a circle on the image and cropping.\n",
    "- Verify the geographic coordinate by cropping a Web-Map-Service frame.\n",
    "- Writing both images and showing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_and_mark_image( id, image, pix, crop_size ):\n",
    "\n",
    "    # Define image path\n",
    "    img_path = f'./crops/gcp_{id}_pixel_{pix[0]}_{pix[1]}.jpg'\n",
    "    if overwrite_crops == False and os.path.exists( img_path ):\n",
    "        return\n",
    "    \n",
    "    #  Crop the image\n",
    "    r = [[max( 0, pix[1] - crop_size[0]), \n",
    "          min( image.shape[0]-1, pix[1] + crop_size[0])],\n",
    "         [max( 0, pix[0] - crop_size[1]),\n",
    "          min( image.shape[1]-1, pix[0] + crop_size[1])]]\n",
    "\n",
    "    center = [ min( pix[1], crop_size[0] ),\n",
    "               min( pix[0], crop_size[1] ) ]\n",
    "    \n",
    "    new_img = image[ r[0][0]:r[0][1], r[1][0]:r[1][1], : ]\n",
    "    new_img = cv2.cvtColor( new_img, cv2.COLOR_RGB2BGR )\n",
    "\n",
    "    #  Draw a circle\n",
    "    new_img = cv2.circle( new_img, center, 10, (0, 0, 255 ), 3 )\n",
    "\n",
    "    #  Write to disk\n",
    "    cv2.imwrite( img_path, new_img )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_wms_coord( id, lla ):\n",
    "\n",
    "    output_path = f'./crops/gcp_{id}_lla.tif'\n",
    "    if overwrite_crops == False and os.path.exists( output_path ):\n",
    "        return\n",
    "\n",
    "    crop_size = [200,200]\n",
    "        \n",
    "    wms_inst = wms.WMS( url          = wms_url,\n",
    "                        epsg_code    = 32613,\n",
    "                        center_ll    = lla,\n",
    "                        win_size_pix = crop_size,\n",
    "                        gsd          = 0.5,\n",
    "                        layers       = wms_layers,\n",
    "                        format       = wms_format )\n",
    "    url = wms_inst.get_map_url()\n",
    "    tif_bytes = urlopen(url).read()\n",
    "\n",
    "    with open( output_path, 'wb' ) as fout:\n",
    "        fout.write( tif_bytes )\n",
    "\n",
    "    tmp_img = cv2.imread( output_path, cv2.IMREAD_COLOR )\n",
    "    tmp_img = cv2.circle( tmp_img, [int(crop_size[0]/2), int(crop_size[1]/2)], 5, (0, 0, 255 ), 3 )\n",
    "    cv2.imwrite( output_path, tmp_img )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists( 'crops' ):\n",
    "    os.system( 'mkdir crops' )\n",
    "\n",
    "pbar = tqdm.tqdm( total = gcp_df.shape[0] )\n",
    "index = 0\n",
    "for gcp in gcp_df.itertuples():\n",
    "\n",
    "    pix = np.array( [ gcp.PX, gcp.PY ], dtype = np.int32 )\n",
    "    lla = np.array( [ gcp.Longitude, gcp.Latitude, gcp.Elevation ], dtype = np.float64 )\n",
    "\n",
    "    #  Crop scene\n",
    "    crop_and_mark_image( index, img_bands, pix, crop_size = [100,100] )\n",
    "    crop_wms_coord( index, lla )\n",
    "    \n",
    "    index += 1\n",
    "    pbar.update( 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pbar = tqdm.tqdm( total = gcp_df.shape[0] )\n",
    "for ID in range( 0, gcp_df.shape[0] ):\n",
    "\n",
    "    fig2 = sp.make_subplots( rows = 1, cols = 2 )\n",
    "    \n",
    "    img1 = cv2.imread( glob.glob( f'./crops/gcp_{ID}_pixel*' )[0], cv2.IMREAD_COLOR )\n",
    "    img2 = cv2.imread( glob.glob( f'./crops/gcp_{ID}_lla*' )[0], cv2.IMREAD_COLOR )\n",
    "\n",
    "    fig2.add_trace( go.Image( z = img1 ), row = 1, col = 1 )\n",
    "    fig2.add_trace( go.Image( z = img2 ), row = 1, col = 2 )\n",
    "    fig2.update_layout( title = f'GCP {ID} Analysis, Pixel vs LLA',\n",
    "                        margin=dict(l=5, r=5, t=20, b=5),\n",
    "                        width = 500,\n",
    "                        height = 500 )\n",
    "    fig2.write_image( f'./crops/gcp_{ID}_merged.jpg' )\n",
    "    pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./crops/gcp_0_merged.jpg\" style=\"height:600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct a System of Linear Equation\n",
    "\n",
    "The core operation is for the World-to-Pixel projection.  These equations are constructed based on the following inputs.\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "The Rational Polynomial Coefficients\n",
    "equations are defined by the following:\n",
    "\n",
    "$$\n",
    "X_P = \\frac{}{}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bboxes( gcps ):\n",
    "\n",
    "    #  Compute bounding box\n",
    "    pix_bbox = None\n",
    "    lla_bbox = None\n",
    "\n",
    "    for gcp in gcp_df.itertuples():\n",
    "\n",
    "        pix = np.array( [ gcp.PX, gcp.PY ], dtype = np.int32 )\n",
    "        lla = np.array( [ gcp.Longitude, gcp.Latitude, gcp.Elevation ], dtype = np.float64 )\n",
    "        \n",
    "        if pix_bbox is None:\n",
    "            pix_bbox = geom.Rectangle( pix )\n",
    "        else:\n",
    "            pix_bbox.add_point( pix )\n",
    "            \n",
    "        if lla_bbox is None:\n",
    "            lla_bbox = geom.Rectangle( lla )\n",
    "        else:\n",
    "            lla_bbox.add_point( lla )\n",
    "\n",
    "    return pix_bbox, lla_bbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pix_bbox, lla_bbox = compute_bboxes( gcp_df )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def solve( gcp_df ):\n",
    "\n",
    "\n",
    "    #  Get the mean of the points\n",
    "    lla_gnd_mean = lla_bbox.mean_point()\n",
    "    pix_mean = pix_bbox.mean_point()\n",
    "\n",
    "    logger.info( f'Mean LLA Ground Coordinate: {lla_gnd_mean}' )\n",
    "    logger.info( f'Mean Pixel Coordinates: {pix_mean}' )\n",
    "\n",
    "    adj_pixels = []\n",
    "    adj_gnd_lla = []\n",
    "\n",
    "    max_delta_lla = np.zeros( len(lla_bbox.size) )\n",
    "    \n",
    "    for gcp in gcp_df.itertuples():\n",
    "\n",
    "        #  Create nparray point\n",
    "        pix = np.array( [ gcp.PX, gcp.PY ], dtype = np.int32 )\n",
    "        lla = np.array( [ gcp.Longitude, gcp.Latitude, gcp.Elevation ], dtype = np.float64 )\n",
    "\n",
    "        #  Adjust point from mean\n",
    "        d_lla = ( lla - lla_bbox.mean_point() )\n",
    "        d_pix = ( pix - pix_bbox.mean_point() ) / ( pix_bbox.size / 2.0 )\n",
    "\n",
    "        #  Update our maximum delta\n",
    "        max_delta_lla = np.maximum( max_delta_lla, np.abs( d_lla ) )\n",
    "\n",
    "        #  Append point to list of deltas\n",
    "        adj_gnd_lla.append( d_lla )\n",
    "        adj_pixels.append( d_pix )\n",
    "\n",
    "    logger.info( f'Max LLA Delta: {max_delta_lla}' )\n",
    "\n",
    "    # Prevent division by zero\n",
    "    if max_delta_lla[2] < 1:\n",
    "        max_delta_lla[2] = 1\n",
    "    \n",
    "\n",
    "    #  Normalize points\n",
    "    norm_gnd_lla = []\n",
    "    for x in range( len( adj_gnd_lla ) ):\n",
    "        for idx in range( len( max_delta_lla ) ):\n",
    "            norm_gnd_lla.append( adj_gnd_lla[x] / max_delta_lla[idx] )\n",
    "\n",
    "    #  Setup model\n",
    "    model = RPC00B.from_components( pix_bbox.mean_point(),\n",
    "                                    lla_bbox.mean_point(),\n",
    "                                    pix_bbox.size[0],\n",
    "                                    pix_bbox.size[1],\n",
    "                                    max_delta_lla )\n",
    "\n",
    "    logger.info( model )\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
